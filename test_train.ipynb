{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import torch.nn.init as init\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from utils.dataloader import *\n",
    "#use AUC for AUC and CI, auc2 for precision, AUC and CI, auc3 precision auc and CI\n",
    "from utils.auc import *\n",
    "from utils import new_transforms\n",
    "import argparse\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngpu = 1\n",
    "nc = 3\n",
    "imgSize = 299\n",
    "\n",
    "step_freq = 20000000\n",
    "\n",
    "\n",
    "root_dir = '/gpfs/data/abl/deepomics/tsirigoslab/histopathology/Tiles/LungTilesSorted/'\n",
    "num_classes = 3\n",
    "tile_dict_path = '/gpfs/data/abl/deepomics/tsirigoslab/histopathology/Tiles/Lung_FileMappingDict.p'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "manualSeed = random.randint(1, 10000) # fix seed\n",
    "\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from: Solid_Tissue_Normal\n",
      "number of samples: 73015\n",
      "Loading from: TCGA-LUSC\n",
      "number of samples: 204134\n",
      "Loading from: TCGA-LUAD\n",
      "number of samples: 186044\n",
      "Finished loading train dataset: 463193 samples\n",
      "Loading from: Solid_Tissue_Normal\n",
      "number of samples: 13542\n",
      "Loading from: TCGA-LUSC\n",
      "number of samples: 50047\n",
      "Loading from: TCGA-LUAD\n",
      "number of samples: 41918\n",
      "Finished loading valid dataset: 105507 samples\n",
      "Class encoding:\n",
      "{'Solid_Tissue_Normal': 0, 'TCGA-LUAD': 1, 'TCGA-LUSC': 2}\n"
     ]
    }
   ],
   "source": [
    "# Random data augmentation\n",
    "augment = transforms.Compose([new_transforms.Resize((imgSize, imgSize)),\n",
    "                              transforms.RandomHorizontalFlip(),\n",
    "                              new_transforms.RandomRotate(),\n",
    "                              new_transforms.ColorJitter(0.25, 0.25, 0.25, 0.05),\n",
    "                              transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "transform = transforms.Compose([new_transforms.Resize((imgSize,imgSize)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "data = {}\n",
    "loaders = {}\n",
    "\n",
    "for dset_type in ['train', 'valid']:\n",
    "    if dset_type == 'train' and True:\n",
    "        data[dset_type] = TissueData(root_dir, dset_type, transform = augment, metadata=False, test_valid=False)\n",
    "    else:\n",
    "        data[dset_type] = TissueData(root_dir, dset_type, transform = transform, metadata=False, test_valid=False)\n",
    "\n",
    "    loaders[dset_type] = torch.utils.data.DataLoader(data[dset_type], batch_size=32, shuffle=True)\n",
    "    print('Finished loading %s dataset: %s samples' % (dset_type, len(data[dset_type])))\n",
    "\n",
    "class_to_idx = data['train'].class_to_idx\n",
    "classes = data['train'].classes\n",
    "\n",
    "print('Class encoding:')\n",
    "print(class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Solid_Tissue_Normal', 'TCGA-LUAD', 'TCGA-LUSC']\n"
     ]
    }
   ],
   "source": [
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/share/apps/python/gpu/3.6.5/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Custom weights initialization\n",
    "\n",
    "def init_model(model):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m,nn.Conv2d):\n",
    "            m.weight.data = init.xavier_normal(m.weight.data)\n",
    "        elif isinstance(m,nn.BatchNorm2d):\n",
    "            m.weight.data.normal_(-0.1, 0.1)\n",
    "\n",
    "class BasicConv2d(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, pool, **kwargs):\n",
    "        super(BasicConv2d, self).__init__()\n",
    "\n",
    "        self.pool = pool\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, **kwargs)\n",
    "        self.bn = nn.BatchNorm2d(out_channels, eps=0.001)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "\n",
    "        if self.pool:\n",
    "            x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        x = self.relu(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "# Define model\n",
    "class cancer_CNN(nn.Module):\n",
    "    def __init__(self, nc, imgSize, ngpu):\n",
    "        super(cancer_CNN, self).__init__()\n",
    "        self.nc = nc\n",
    "        self.imgSize = imgSize\n",
    "        self.ngpu = ngpu\n",
    "        #self.data = opt.data\n",
    "        self.conv1 = BasicConv2d(nc, 16, False, kernel_size=5, padding=1, stride=2, bias=True)\n",
    "        self.conv2 = BasicConv2d(16, 32, False, kernel_size=3, bias=True)\n",
    "        self.conv3 = BasicConv2d(32, 64, True, kernel_size=3, padding=1, bias=True)\n",
    "        self.conv4 = BasicConv2d(64, 64, True, kernel_size=3, padding=1, bias=True)\n",
    "        self.conv5 = BasicConv2d(64, 128, True, kernel_size=3, padding=1, bias=True)\n",
    "        self.conv6 = BasicConv2d(128, 64, True, kernel_size=3, padding=1, bias=True)\n",
    "        self.linear = nn.Linear(5184, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.conv6(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "# Create model objects\n",
    "model = cancer_CNN(nc, imgSize, ngpu)\n",
    "init_model(model)\n",
    "model.train()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Load checkpoint models if needed\n",
    "\n",
    "\n",
    "model.cuda()\n",
    "\n",
    "# Set up optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.5, 0.999))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tile_probability(tile_path):\n",
    "\n",
    "    \"\"\"\n",
    "    Returns an array of probabilities for each class given a tile\n",
    "    @param tile_path: Filepath to the tile\n",
    "    @return: A ndarray of class probabilities for that tile\n",
    "    \"\"\"\n",
    "\n",
    "    # Some tiles are empty with no path, return nan\n",
    "    if tile_path == '':\n",
    "        return np.full(num_classes, np.nan)\n",
    "\n",
    "    tile_path = root_dir + tile_path\n",
    "\n",
    "    with open(tile_path, 'rb') as f:\n",
    "        with Image.open(f) as img:\n",
    "            img = img.convert('RGB')\n",
    "\n",
    "    # Model expects a 4D tensor, unsqueeze first dimension\n",
    "    img = transform(img).unsqueeze(0)\n",
    "\n",
    "    img = img.cuda()\n",
    "\n",
    "    # Turn output into probabilities with softmax\n",
    "    var_img = Variable(img, volatile=True)\n",
    "    output = F.softmax(model(var_img)).data.squeeze(0)\n",
    "\n",
    "    return output.cpu().numpy()\n",
    "\n",
    "# Load tile dictionary\n",
    "\n",
    "with open(tile_dict_path, 'rb') as f:\n",
    "    tile_dict = pickle.load(f)\n",
    "\n",
    "def aggregate(file_list, method):\n",
    "\n",
    "    \"\"\"\n",
    "    Given a list of files, return scores for each class according to the\n",
    "    method and labels for those files.\n",
    "    @param file_list: A list of file paths to do predictions on\n",
    "    @param method: 'average' - returns the average probability score across\n",
    "                               all tiles for that file\n",
    "                   'max' - predicts each tile to be the class of the maximum\n",
    "                           score, and returns the proportion of tiles for\n",
    "                           each class\n",
    "    @return: a ndarray of class probabilities for all files in the list\n",
    "             a ndarray of the labels\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    for file in file_list:\n",
    "        tile_paths, label = tile_dict[file]\n",
    "\n",
    "        folder = classes[label]\n",
    "\n",
    "        def add_folder(tile_path):\n",
    "            if tile_path == '':\n",
    "                return ''\n",
    "            else:\n",
    "                return folder + '/' + tile_path\n",
    "\n",
    "        # Add the folder for the class name in front\n",
    "        add_folder_v = np.vectorize(add_folder)\n",
    "        tile_paths = add_folder_v(tile_paths)\n",
    "\n",
    "        # Get the probability array for the file\n",
    "        prob_v = np.vectorize(get_tile_probability, otypes=[np.ndarray])\n",
    "        probabilities = prob_v(tile_paths)\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        imgSize = probabilities.shape()\n",
    "        newShape = (imgSize[0], imgSize[1], 3)\n",
    "        probabilities = np.reshape(np.stack(probabilities.flat), newShape)\n",
    "        \"\"\"\n",
    "\n",
    "        if method == 'average':\n",
    "            probabilities = np.stack(probabilities.flat)\n",
    "            prediction = np.nanmean(probabilities, axis = 0)\n",
    "\n",
    "        elif method == 'max':\n",
    "            probabilities = np.stack(probabilities.flat)\n",
    "            probabilities = probabilities[~np.isnan(probabilities).all(axis=1)]\n",
    "            votes = np.nanargmax(probabilities, axis=1)\n",
    "            \n",
    "            out = np.array([sum(votes == i) for i in range(num_classes)])\n",
    "            prediction = out / out.sum()\n",
    "\n",
    "        else:\n",
    "            raise ValueError('Method not valid')\n",
    "\n",
    "        predictions.append(prediction)\n",
    "        true_labels.append(label)\n",
    "\n",
    "    return np.array(predictions), np.array(true_labels)\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "def early_stop(val_history, t=3, required_progress=0.0001):\n",
    "\n",
    "    \"\"\"\n",
    "    Stop the training if there is no non-trivial progress in k steps\n",
    "    @param val_history: a list contains all the historical validation auc\n",
    "    @param required_progress: the next auc should be higher than the previous by \n",
    "        at least required_progress amount to be non-trivial\n",
    "    @param t: number of training steps \n",
    "    @return: a boolean indicates if the model should early stop\n",
    "    \"\"\"\n",
    "    \n",
    "    if (len(val_history) > t+1):\n",
    "        differences = []\n",
    "        for x in range(1, t+1):\n",
    "            differences.append(val_history[-x]-val_history[-(x+1)])\n",
    "        differences = [y < required_progress for y in differences]\n",
    "        if sum(differences) == t: \n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "stop_training = False\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n",
      "Wed Aug 14 17:53:13 2019\n",
      "1565819593.9164448\n",
      "<torch.utils.data.dataloader._DataLoaderIter object at 0x7e292c1cbf28>\n",
      "14475\n",
      "tensor(0.9032, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][1/14475] Training Loss: 0.903194\n",
      "tensor(1.0196, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][2/14475] Training Loss: 1.019568\n",
      "tensor(0.8736, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][3/14475] Training Loss: 0.873595\n",
      "tensor(0.9566, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][4/14475] Training Loss: 0.956565\n",
      "tensor(0.9175, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][5/14475] Training Loss: 0.917497\n",
      "tensor(0.9562, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][6/14475] Training Loss: 0.956221\n",
      "tensor(1.0273, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][7/14475] Training Loss: 1.027304\n",
      "tensor(0.8861, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][8/14475] Training Loss: 0.886058\n",
      "tensor(1.0820, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][9/14475] Training Loss: 1.082000\n",
      "tensor(1.0198, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][10/14475] Training Loss: 1.019783\n",
      "tensor(0.8828, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][11/14475] Training Loss: 0.882755\n",
      "tensor(0.8868, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][12/14475] Training Loss: 0.886785\n",
      "tensor(0.9572, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][13/14475] Training Loss: 0.957184\n",
      "tensor(0.9383, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][14/14475] Training Loss: 0.938339\n",
      "tensor(0.8921, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][15/14475] Training Loss: 0.892055\n",
      "tensor(0.9261, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][16/14475] Training Loss: 0.926103\n",
      "tensor(0.9307, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][17/14475] Training Loss: 0.930692\n",
      "tensor(0.9995, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][18/14475] Training Loss: 0.999470\n",
      "tensor(0.8390, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][19/14475] Training Loss: 0.839045\n",
      "tensor(0.8897, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][20/14475] Training Loss: 0.889664\n",
      "tensor(1.0565, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][21/14475] Training Loss: 1.056463\n",
      "tensor(0.8927, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][22/14475] Training Loss: 0.892707\n",
      "tensor(0.9254, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][23/14475] Training Loss: 0.925380\n",
      "tensor(1.0234, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][24/14475] Training Loss: 1.023404\n",
      "tensor(0.9039, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][25/14475] Training Loss: 0.903903\n",
      "tensor(0.8620, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][26/14475] Training Loss: 0.861973\n",
      "tensor(0.9758, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][27/14475] Training Loss: 0.975821\n",
      "tensor(0.8673, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][28/14475] Training Loss: 0.867305\n",
      "tensor(0.9601, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][29/14475] Training Loss: 0.960147\n",
      "tensor(1.0277, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][30/14475] Training Loss: 1.027665\n",
      "tensor(1.1669, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][31/14475] Training Loss: 1.166912\n",
      "tensor(0.9095, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][32/14475] Training Loss: 0.909485\n",
      "tensor(0.9043, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][33/14475] Training Loss: 0.904268\n",
      "tensor(0.9576, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][34/14475] Training Loss: 0.957558\n",
      "tensor(0.9782, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][35/14475] Training Loss: 0.978184\n",
      "tensor(0.8838, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][36/14475] Training Loss: 0.883762\n",
      "tensor(1.1181, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][37/14475] Training Loss: 1.118067\n",
      "tensor(0.9028, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][38/14475] Training Loss: 0.902796\n",
      "tensor(0.9051, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][39/14475] Training Loss: 0.905074\n",
      "tensor(0.9902, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][40/14475] Training Loss: 0.990188\n",
      "tensor(0.9491, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][41/14475] Training Loss: 0.949130\n",
      "tensor(0.8919, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][42/14475] Training Loss: 0.891887\n",
      "tensor(0.8505, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][43/14475] Training Loss: 0.850481\n",
      "tensor(0.8509, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][44/14475] Training Loss: 0.850939\n",
      "tensor(0.9917, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][45/14475] Training Loss: 0.991739\n",
      "tensor(0.8356, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][46/14475] Training Loss: 0.835589\n",
      "tensor(0.8829, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][47/14475] Training Loss: 0.882932\n",
      "tensor(0.9573, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][48/14475] Training Loss: 0.957332\n",
      "tensor(0.9001, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][49/14475] Training Loss: 0.900082\n",
      "tensor(0.9065, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][50/14475] Training Loss: 0.906541\n",
      "tensor(0.9184, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][51/14475] Training Loss: 0.918389\n",
      "tensor(0.9940, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][52/14475] Training Loss: 0.994004\n",
      "tensor(0.8407, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][53/14475] Training Loss: 0.840702\n",
      "tensor(0.8806, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][54/14475] Training Loss: 0.880611\n",
      "tensor(0.9183, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][55/14475] Training Loss: 0.918263\n",
      "tensor(0.8847, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][56/14475] Training Loss: 0.884675\n",
      "tensor(0.8953, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][57/14475] Training Loss: 0.895348\n",
      "tensor(1.0493, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][58/14475] Training Loss: 1.049251\n",
      "tensor(0.9073, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][59/14475] Training Loss: 0.907264\n",
      "tensor(0.8039, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][60/14475] Training Loss: 0.803909\n",
      "tensor(0.9189, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][61/14475] Training Loss: 0.918904\n",
      "tensor(0.8322, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][62/14475] Training Loss: 0.832225\n",
      "tensor(0.9400, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][63/14475] Training Loss: 0.939966\n",
      "tensor(0.8333, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][64/14475] Training Loss: 0.833346\n",
      "tensor(0.8346, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][65/14475] Training Loss: 0.834607\n",
      "tensor(0.7924, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][66/14475] Training Loss: 0.792420\n",
      "tensor(1.1542, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][67/14475] Training Loss: 1.154224\n",
      "tensor(0.7995, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][68/14475] Training Loss: 0.799454\n",
      "tensor(0.9042, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][69/14475] Training Loss: 0.904201\n",
      "tensor(0.7908, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][70/14475] Training Loss: 0.790755\n",
      "tensor(1.0316, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][71/14475] Training Loss: 1.031553\n",
      "tensor(1.0015, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][72/14475] Training Loss: 1.001467\n",
      "tensor(0.9823, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][73/14475] Training Loss: 0.982256\n",
      "tensor(0.8458, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][74/14475] Training Loss: 0.845790\n",
      "tensor(1.0011, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][75/14475] Training Loss: 1.001085\n",
      "tensor(0.8593, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][76/14475] Training Loss: 0.859350\n",
      "tensor(0.8037, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][77/14475] Training Loss: 0.803698\n",
      "tensor(0.7952, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][78/14475] Training Loss: 0.795183\n",
      "tensor(0.9394, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][79/14475] Training Loss: 0.939391\n",
      "tensor(0.9805, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][80/14475] Training Loss: 0.980477\n",
      "tensor(0.9573, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][81/14475] Training Loss: 0.957329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8541, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][82/14475] Training Loss: 0.854140\n",
      "tensor(0.8161, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][83/14475] Training Loss: 0.816101\n",
      "tensor(0.8269, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][84/14475] Training Loss: 0.826914\n",
      "tensor(1.0192, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][85/14475] Training Loss: 1.019155\n",
      "tensor(1.0190, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][86/14475] Training Loss: 1.018974\n",
      "tensor(0.8885, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][87/14475] Training Loss: 0.888496\n",
      "tensor(0.9259, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][88/14475] Training Loss: 0.925857\n",
      "tensor(0.9098, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][89/14475] Training Loss: 0.909754\n",
      "tensor(0.8718, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][90/14475] Training Loss: 0.871757\n",
      "tensor(1.0185, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][91/14475] Training Loss: 1.018530\n",
      "tensor(0.8601, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][92/14475] Training Loss: 0.860128\n",
      "tensor(1.0522, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][93/14475] Training Loss: 1.052151\n",
      "tensor(0.8786, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][94/14475] Training Loss: 0.878649\n",
      "tensor(0.9812, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][95/14475] Training Loss: 0.981169\n",
      "tensor(0.8241, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][96/14475] Training Loss: 0.824119\n",
      "tensor(1.1276, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][97/14475] Training Loss: 1.127608\n",
      "tensor(0.8432, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][98/14475] Training Loss: 0.843234\n",
      "tensor(0.9748, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][99/14475] Training Loss: 0.974811\n",
      "tensor(0.9500, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][100/14475] Training Loss: 0.950002\n",
      "tensor(0.9307, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][101/14475] Training Loss: 0.930678\n",
      "tensor(0.9536, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][102/14475] Training Loss: 0.953636\n",
      "tensor(0.8956, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][103/14475] Training Loss: 0.895574\n",
      "tensor(0.7998, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][104/14475] Training Loss: 0.799810\n",
      "tensor(0.9374, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][105/14475] Training Loss: 0.937369\n",
      "tensor(1.1070, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][106/14475] Training Loss: 1.107034\n",
      "tensor(0.8603, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][107/14475] Training Loss: 0.860325\n",
      "tensor(0.8886, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][108/14475] Training Loss: 0.888568\n",
      "tensor(0.8123, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][109/14475] Training Loss: 0.812348\n",
      "tensor(0.8798, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][110/14475] Training Loss: 0.879805\n",
      "tensor(0.9098, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][111/14475] Training Loss: 0.909758\n",
      "tensor(0.9581, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][112/14475] Training Loss: 0.958086\n",
      "tensor(0.8391, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][113/14475] Training Loss: 0.839129\n",
      "tensor(0.8083, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[1/25][114/14475] Training Loss: 0.808348\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-ebb29628cdf0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_iter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gpfs/share/apps/python/gpu/3.6.5/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gpfs/share/apps/python/gpu/3.6.5/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gpfs/scratch/bilals01/test-repo/PathCNN/utils/dataloader.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatapoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;31m# Load image from filepath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gpfs/scratch/bilals01/test-repo/PathCNN/utils/dataloader.py\u001b[0m in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gpfs/share/apps/python/gpu/3.6.5/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    877\u001b[0m         \"\"\"\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"P\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gpfs/share/apps/python/gpu/3.6.5/lib/python3.6/site-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_AUC = 0.0\n",
    "\n",
    "print('Starting training')\n",
    "start = time.time()\n",
    "local_time = time.ctime(start)\n",
    "print(local_time)\n",
    "\n",
    "print(time.time())\n",
    "for epoch in range(1,25):\n",
    "    data_iter = iter(loaders['train'])\n",
    "    print(data_iter)\n",
    "    i = 0\n",
    "    \n",
    "    print(len(loaders['train']))\n",
    "    \n",
    "    while i < len(loaders['train']):\n",
    "        model.train()\n",
    "        img, label = data_iter.next()\n",
    "        i += 1\n",
    "\n",
    "        # Drop the last batch if it's not the same size as the batchsize\n",
    "        if img.size(0) != 32:\n",
    "            break\n",
    "\n",
    "        img = img.cuda()\n",
    "        label = label.cuda()\n",
    "\n",
    "        input_img = Variable(img)\n",
    "        target_label = Variable(label)\n",
    "\n",
    "        train_loss = criterion(model(input_img), target_label)\n",
    "        print(train_loss)\n",
    "        # Zero gradients then backward pass\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "      \n",
    "        correc=0\n",
    "        total=0\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        print('[%d/%d][%d/%d] Training Loss: %f'\n",
    "               % (epoch, 25, i, len(loaders['train']), train_loss.item()))\n",
    "        ii=i+((epoch)*len(loaders['train']))\n",
    "        #get validation AUC every step_freq \n",
    "        if ii % step_freq == 0:\n",
    "            val_predictions, val_labels = aggregate(data['valid'].filenames, method='average')\n",
    "\n",
    "            data_ = np.column_stack((data['valid'].filenames,np.asarray(val_predictions),np.asarray(val_labels)))\n",
    "            #data_.dump(open('{0}/outputs/val_pred_label_avg_step_{1}.npy'.format(1,str(ii)), 'wb'))\n",
    "            #torch.save(model.state_dict(), '{0}/checkpoints/step_{1}.pth'.format(1, str(ii)))           \n",
    "            #print('validation scores:')\n",
    "\n",
    "            #roc_auc = get_auc('{0}/images/val_roc_step_{1}.jpg'.format(opt.experiment,epoch), val_predictions, val_labels, classes = range(num_classes))\n",
    "            for k, v in roc_auc.items(): \n",
    "                if k in range(num_classes):\n",
    "                    k = classes[k] \n",
    "                #experiment.log_metric(\"{0} AUC\".format(k), v)\n",
    "                print('%s AUC: %0.4f' % (k, v))\n",
    "\n",
    "    #save the checkpoint at every epoch\n",
    "    #torch.save(model.state_dict(), '{0}/checkpoints/epoch_{1}.pth'.format(opt.experiment, str(epoch)))\n",
    "\n",
    "    #print(time.time())\n",
    "    # Get validation AUC once per epoch\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Final evaluation\n",
    "print('Finished training, best AUC: %0.4f' % (best_AUC))\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import threading\n",
    "threading.activeCount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parser = argparse.ArgumentParser()\n",
    "#parser.add_argument('--experiment', default='', help=\"name of experiment to test\")\n",
    "#parser.add_argument('--model', default='', help=\"name of model to test\")\n",
    "#parser.add_argument('--root_dir', type=str, default='<ROOT_PATH><CANCER_TYPE>TilesSorted/', help='Data directory .../dataTilesSorted/')\n",
    "#parser.add_argument('--num_class', type=int, default=2, help='number of classes ')\n",
    "#parser.add_argument('--tile_dict_path', type=str, default='\"<ROOT_PATH><CANCER_TYPE>_FileMappingDict.p', help='Tile dictinory path')\n",
    "#parser.add_argument('--val', type=str, default='test', help='validation set')\n",
    "\n",
    "#opt = parser.parse_args()\n",
    "\n",
    "\n",
    "#test_val = str(opt.val)\n",
    "\n",
    "imgSize = 299\n",
    "\n",
    "transform = transforms.Compose([new_transforms.Resize((imgSize,imgSize)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "test_data = TissueData(root_dir, 'test', transform = transform, metadata=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "classes = test_data.classes\n",
    "class_to_idx = test_data.class_to_idx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
