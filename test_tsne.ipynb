{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from sklearn.manifold import TSNE\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import torch.nn.init as init\n",
    "from torch.autograd import Variable\n",
    "import argparse\n",
    "import copy\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from PIL import Image\n",
    "from utils.dataloader import *\n",
    "from utils import new_transforms\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "exp_name=\"breast_sub_basal_vs_all_7layers_tr\"\n",
    "test_val=\"valid\"\n",
    "im_size=\"299\"\n",
    "model=\"7layers\"\n",
    "tlog=\"/scratch/sb3923/logs/breast_sub_basal_vs_all_7layers_tr.log\"\n",
    " \n",
    "#breast subtypes\n",
    "root_dir=\"/beegfs/sb3923/DeepCancer/alldata/BreastSubtypes_basal_vs_all/BreastTilesSorted/\"\n",
    "num_class=2 \n",
    "tile_dict_path=\"/beegfs/sb3923/DeepCancer/alldata/BreastSubtypes_basal_vs_all/Breast_FileMappingDict.p\"\n",
    "#--val=${test_val} --imgSize=${im_size} --model_type=${model}\"\n",
    "nexp=\"/scratch/sb3923/experiments/breast_sub_basal_vs_all_7layers_tr\"\n",
    "out=\"/scratch/sb3923/logs/$valid\"\n",
    "    \n",
    "PathToEpoch=\"$/scratch/sb3923/experiments/breast_sub_basal_vs_all_7layers_tr/checkpoints/\"\n",
    "Cmodel=\"epoch_1.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--experiment', default='', help=\"name of experiment to test\")\n",
    "parser.add_argument('--model', default='', help=\"name of model to test\")\n",
    "parser.add_argument('--root_dir', type=str, default='<ROOT_PATH><CANCER_TYPE>TilesSorted/', help='Data directory .../dataTilesSorted/')\n",
    "parser.add_argument('--num_class', type=int, default=2, help='number of classes ')\n",
    "parser.add_argument('--tile_dict_path', type=str, default='\"<ROOT_PATH><CANCER_TYPE>_FileMappingDict.p', help='Tile dictinory path')\n",
    "parser.add_argument('--val', type=str, default='test', help='validation set')\n",
    "parser.add_argument('--train_log', type=str, default='/gpfs/scratch/bilals01/test-repo/logs/exp6_train.log', help='point to the log file created from the training')\n",
    "parser.add_argument('--imgSize', type=int, default=299, help='the height / width of the image to network')\n",
    "parser.add_argument('--model_type',type=str,  default='PathCNN', help='choose the model to train with: PathCNN, alexnet,vgg16')\n",
    "parser.add_argument('--nc', type=int, default=3, help='input image channels (+ concatenated info channels if metadata = True)')\n",
    "parser.add_argument('--ngpu'  , type=int, default=1, help='number of GPUs to use')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from: Basal\n",
      "number of samples: 10114\n",
      "Loading from: non-Basal\n",
      "number of samples: 69738\n",
      "Class encoding:\n",
      "{'non-Basal': 1, 'Basal': 0}\n",
      "after tissuedata\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#opt = parser.parse_args()\n",
    "nc = 3\n",
    "root_dir = root_dir\n",
    "num_classes = 2\n",
    "tile_dict_path = tile_dict_path\n",
    "tl_file = tlog\n",
    "test_val = test_val\n",
    "imgSize = 299\n",
    "ngpu = 1\n",
    "test_val = 'test'\n",
    "\n",
    "\n",
    "imgSize = 299\n",
    "\n",
    "transform = transforms.Compose([new_transforms.Resize((imgSize,imgSize)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "#use Tissuedata2 for ownsampled data, for test use the whole data\n",
    "test_data = TissueData(root_dir, test_val, train_log=tl_file, transform = transform, metadata=False)\n",
    "#test_data = TissueData(root_dir, test_val, train_log='', transform = transform, metadata=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=False, num_workers=8)\n",
    "\n",
    "#os.chdir(\"/scratch/sb3923/deep-cancer/tsne_figures/\")\n",
    "#pickle.dump( test_data.filenames, open( \"test_data.p\", \"wb\" ) )\n",
    "\n",
    "classes = test_data.classes\n",
    "\n",
    "class_to_idx = test_data.class_to_idx\n",
    " \n",
    "print('Class encoding:')\n",
    "print(class_to_idx)\n",
    "\n",
    "print('after tissuedata')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_tile_probability(tile_path):\n",
    "\n",
    "    \"\"\"\n",
    "    Returns an array of probabilities for each class given a tile\n",
    "\n",
    "    @param tile_path: Filepath to the tile\n",
    "    @return: A ndarray of class probabilities for that tile\n",
    "    \"\"\"\n",
    "\n",
    "    # Some tiles are empty with no path, return nan\n",
    "    if tile_path == '':\n",
    "        return np.full(num_classes, np.nan)\n",
    "\n",
    "    tile_path = root_dir + tile_path\n",
    "\n",
    "    with open(tile_path, 'rb') as f:\n",
    "        with Image.open(f) as img:\n",
    "            img = img.convert('RGB')\n",
    "\n",
    "    # Model expects a 4D tensor, unsqueeze first dimension\n",
    "    img = transform(img).unsqueeze(0)\n",
    "    img = img.cuda()\n",
    "\n",
    "    # Turn output into probabilities with softmax\n",
    "    var_img = Variable(img, volatile=True)\n",
    "    output = F.softmax(model(var_img)[0]).data.squeeze(0) \n",
    "    return output.cpu().numpy()\n",
    "    #original: \n",
    "    #var_img = Variable(img, volatile=True)\n",
    "    #output = F.softmax(model(var_img)).data.squeeze(0)\n",
    "\n",
    "    #return output.cpu().numpy()\n",
    "\n",
    "\n",
    "def get_tile_probability2(tile_path):\n",
    "    \"\"\"\n",
    "    Returns an array of probabilities for each class given a tile\n",
    "\n",
    "    @param tile_path: Filepath to the tile\n",
    "    @return: A ndarray of class probabilities for that tile\n",
    "    \"\"\"\n",
    "    # Some tiles are empty with no path, return nan\n",
    "    if tile_path == '':\n",
    "        return np.full(1024, np.nan)\n",
    "\n",
    "    tile_path = root_dir + tile_path\n",
    "\n",
    "    with open(tile_path, 'rb') as f:\n",
    "        with Image.open(f) as img:\n",
    "            img = img.convert('RGB')\n",
    "    # Model expects a 4D tensor, unsqueeze first dimension\n",
    "    img = transform(img).unsqueeze(0)\n",
    "    img = img.cuda()\n",
    "    # Turn output into probabilities with softmax\n",
    "    var_img = Variable(img, volatile=True)\n",
    "    \n",
    "\n",
    "    viz = (model(var_img)[1]).squeeze(0)#torch.FloatTensor of size 1x5184 \n",
    "    return viz.data.cpu().numpy() #numpy.ndarray\n",
    "\n",
    "\n",
    "\n",
    "with open(tile_dict_path, 'rb') as f:\n",
    "    tile_dict = pickle.load(f)\n",
    "\n",
    "\n",
    "def aggregate(file_list, method):\n",
    "\n",
    "    \"\"\"\n",
    "    Given a list of files, return scores for each class according to the\n",
    "    method and labels for those files.\n",
    "\n",
    "    @param file_list: A list of file paths to do predictions on\n",
    "    @param method: 'average' - returns the average probability score across\n",
    "                               all tiles for that file\n",
    "                   'max' - predicts each tile to be the class of the maximum\n",
    "                           score, and returns the proportion of tiles for\n",
    "                           each class\n",
    "\n",
    "    @return: a ndarray of class probabilities for all files in the list\n",
    "             a ndarray of the labels\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    last_layer = []\n",
    "    file_name = []\n",
    "\n",
    "    for file in file_list:\n",
    "        tile_paths, label = tile_dict[file]\n",
    "\n",
    "        folder = classes[label]\n",
    "\n",
    "        def add_folder(tile_path):\n",
    "            if tile_path == '':\n",
    "                return ''\n",
    "            else:\n",
    "                return folder + '/' + tile_path\n",
    "\n",
    "        # Add the folder for the class name in front\n",
    "        add_folder_v = np.vectorize(add_folder)\n",
    "        tile_paths0 = add_folder_v(tile_paths)\n",
    "\n",
    "        # Get the probability array for the file\n",
    "        prob_v= np.vectorize(get_tile_probability, otypes=[np.ndarray])\n",
    "        probabilities = prob_v(tile_paths0)\n",
    "        \n",
    "        tile_paths1 = add_folder_v(tile_paths)\n",
    "        \n",
    "        prob_v2 = np.vectorize(get_tile_probability2, otypes=[np.ndarray])\n",
    "        lastlayer = prob_v2(tile_paths1)\n",
    "\n",
    "        probabilities = np.stack(probabilities.flat)\n",
    "        prediction = np.nanmean(probabilities, axis = 0)\n",
    "\n",
    "        tile_label = np.argmax(probabilities,axis=1)\n",
    "        #last layer\n",
    "        lastlayer = np.stack(lastlayer.flat)\n",
    "        a = lastlayer[np.ix_(label == tile_label),:]\n",
    "\n",
    "        if (np.squeeze(a)).ndim>1:\n",
    "            lastlayerweights = np.nanmean(np.squeeze(a), axis = 0)\n",
    "            #lastlayer = np.stack(lastlayer.flat)\n",
    "            #lastlayerweights = np.nanmean(lastlayer, axis = 0)\n",
    "\n",
    "            predictions.append(prediction)\n",
    "            true_labels.append(label)\n",
    "            last_layer.append(lastlayerweights)\n",
    "            file_name.append(file)\n",
    "\n",
    "    return np.array(predictions), np.array(true_labels), np.array(last_layer),np.array(file_name)\n",
    "    #return np.array(true_labels), np.array(last_layer)\n",
    "\n",
    "\n",
    "\n",
    "class BasicConv2d(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, pool, **kwargs):\n",
    "        super(BasicConv2d, self).__init__()\n",
    "\n",
    "        self.pool = pool\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, **kwargs)\n",
    "        self.bn = nn.BatchNorm2d(out_channels, eps=0.001)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "\n",
    "        if self.pool:\n",
    "            x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        x = self.relu(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "# Define model\n",
    "class cancer_CNN(nn.Module):\n",
    "    def __init__(self, nc, imgSize, ngpu):\n",
    "        super(cancer_CNN, self).__init__()\n",
    "        self.nc = nc\n",
    "        self.imgSize = imgSize\n",
    "        self.ngpu = ngpu\n",
    "        #self.data = 'all'\n",
    "        self.conv1 = BasicConv2d(nc, 16, False, kernel_size=5, padding=1, stride=2, bias=True)\n",
    "        self.conv2 = BasicConv2d(16, 32, False, kernel_size=3, bias=True)\n",
    "        self.conv3 = BasicConv2d(32, 64, True, kernel_size=3, padding=1, bias=True)\n",
    "        self.conv4 = BasicConv2d(64, 64, True, kernel_size=3, padding=1, bias=True)\n",
    "        self.conv5 = BasicConv2d(64, 128, True, kernel_size=3, padding=1, bias=True)\n",
    "        self.conv6 = BasicConv2d(128, 64, True, kernel_size=3, padding=1, bias=True)\n",
    "        self.linear = nn.Linear(5184, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.conv6(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        llw=x\n",
    "        x = self.linear(x)\n",
    "        return x, llw\n",
    "\n",
    "class cancer_CNN_7layers(nn.Module):\n",
    "     def __init__(self, nc, imgSize, ngpu):\n",
    "         super(cancer_CNN_7layers, self).__init__()\n",
    "         self.nc = nc\n",
    "         self.imgSize = imgSize\n",
    "         self.ngpu = ngpu\n",
    "         #self.data = opt.data\n",
    "         self.conv1 = BasicConv2d(nc, 16, False, kernel_size=5, padding=1, stride=2, bias=True)\n",
    "         self.conv2 = BasicConv2d(16, 32, False, kernel_size=3, bias=True)\n",
    "         self.conv3 = BasicConv2d(32, 64, True, kernel_size=3, padding=1, bias=True)\n",
    "         self.conv4 = BasicConv2d(64, 64, True, kernel_size=3, padding=1, bias=True)\n",
    "         self.conv5 = BasicConv2d(64, 128, True, kernel_size=3, padding=1, bias=True)\n",
    "         self.conv6 = BasicConv2d(128, 64, True, kernel_size=3, padding=1, bias=True)\n",
    "         self.conv7 = BasicConv2d(64, 64, True, kernel_size=3, padding=1, bias=True)\n",
    "         self.linear = nn.Linear(1024, num_classes)\n",
    " \n",
    "     def forward(self, x):\n",
    "         x = self.conv1(x)\n",
    "         x = self.conv2(x)\n",
    "         x = self.conv3(x)\n",
    "         x = self.conv4(x)\n",
    "         x = self.conv5(x)\n",
    "         x = self.conv6(x)\n",
    "         x = self.conv7(x)\n",
    "         x = x.view(x.size(0), -1)\n",
    "         llw=x\n",
    "         x = self.linear(x)\n",
    "         return x, llw\n",
    "\n",
    "\n",
    "model = cancer_CNN_7layers(nc, imgSize, ngpu)\n",
    "\n",
    "model.cuda()\n",
    "\n",
    "model_path = nexp + '/checkpoints/' + Cmodel\n",
    "state_dict = torch.load(model_path, map_location=lambda storage, loc: storage)\n",
    "model.load_state_dict(state_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/apps/python3/3.5.3/intel/lib/python3.5/site-packages/ipykernel/__main__.py:124: RuntimeWarning: Mean of empty slice\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "last-layer\n",
      "[[-0.16158456 -0.16323298 -0.20049755 ...,  0.04818501  0.02766555\n",
      "   0.01556775]\n",
      " [-0.24808421 -0.26689126 -0.26869134 ...,  0.05977428  0.05279158\n",
      "   0.05143663]\n",
      " [-0.20628169 -0.23520254 -0.22418504 ..., -0.04810501 -0.05702516\n",
      "  -0.05158457]\n",
      " ..., \n",
      " [ 0.14700307  0.15369099  0.1491881  ..., -0.20098462 -0.177492\n",
      "  -0.17318917]\n",
      " [ 0.1439863   0.17981805  0.16721435 ..., -0.09529176 -0.13053024\n",
      "  -0.13672796]\n",
      " [ 0.18447607  0.18488079  0.1739374  ...,  0.00434389  0.00074014\n",
      "   0.02845178]]\n"
     ]
    }
   ],
   "source": [
    "predictions, labels, fw_lastlayer, file_names = aggregate(test_data.filenames, method='average')\n",
    "print('------------------------------------------------------')\n",
    "print('last-layer')\n",
    "print(fw_lastlayer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'breast_sub_basal_vs_all_7layers_tr'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nexp.split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/sb3923/PathCNN/tsne_data\r\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#os.chdir(\"tsne_data/\")\n",
    " \n",
    "exp_name = nexp.split('/')[-1]\n",
    "pickle.dump( labels, open( \"finalWs_{0}_{1}_{2}.p\".format(exp_name,test_val,Cmodel), \"wb\" ) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "finalWs = fw_lastlayer\n",
    "os.chdir(\"tsne_data/\")\n",
    "pickle.dump( finalWs, open( \"finalWs_{0}_{1}_{2}.p\".format(opt.experiment,opt.val,opt.model), \"wb\" ) )\n",
    "pickle.dump( predictions, open( \"predictions_{0}_{1}_{2}.p\".format(opt.experiment,opt.val,opt.model), \"wb\" ) )\n",
    "pickle.dump( labels, open( \"labels_{0}_{1}_{2}.p\".format(opt.experiment,opt.val,opt.model), \"wb\" ) )\n",
    "pickle.dump( file_names, open( \"file_names_{0}_{1}_{2}.p\".format(opt.experiment,opt.val,opt.model), \"wb\" ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/sb3923/PathCNN/tsne_data\r\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.33290977,  0.66709023],\n",
       "       [ 0.59178376,  0.40821624],\n",
       "       [ 0.40041099,  0.59958901],\n",
       "       [ 0.41988901,  0.58011099],\n",
       "       [ 0.31546959,  0.68453041],\n",
       "       [ 0.53517736,  0.46482264],\n",
       "       [ 0.09809893,  0.90190107],\n",
       "       [ 0.26828116,  0.73171884],\n",
       "       [ 0.25845903,  0.74154097],\n",
       "       [ 0.58529355,  0.41470645],\n",
       "       [ 0.32410907,  0.67589093],\n",
       "       [ 0.31708972,  0.68291028],\n",
       "       [ 0.25304629,  0.74695371],\n",
       "       [ 0.74000518,  0.25999482],\n",
       "       [ 0.18208446,  0.81791554],\n",
       "       [ 0.3602923 ,  0.6397077 ],\n",
       "       [ 0.17681244,  0.82318756],\n",
       "       [ 0.60194043,  0.39805957],\n",
       "       [ 0.64769227,  0.35230773],\n",
       "       [ 0.34080859,  0.65919141],\n",
       "       [ 0.41917276,  0.58082724],\n",
       "       [ 0.35803225,  0.64196775],\n",
       "       [ 0.35005047,  0.64994953],\n",
       "       [ 0.32500136,  0.67499864],\n",
       "       [ 0.71681158,  0.28318842],\n",
       "       [ 0.10473872,  0.89526128],\n",
       "       [ 0.34547851,  0.65452148],\n",
       "       [ 0.16110428,  0.83889572],\n",
       "       [ 0.20798294,  0.79201705],\n",
       "       [ 0.35275649,  0.64724351],\n",
       "       [ 0.36149878,  0.63850122],\n",
       "       [ 0.46047727,  0.53952274],\n",
       "       [ 0.18484696,  0.81515304],\n",
       "       [ 0.11920017,  0.88079983],\n",
       "       [ 0.08514322,  0.91485677],\n",
       "       [ 0.17134442,  0.82865558],\n",
       "       [ 0.11443465,  0.88556535],\n",
       "       [ 0.20688414,  0.79311586],\n",
       "       [ 0.07797335,  0.92202665],\n",
       "       [ 0.10842035,  0.89157965],\n",
       "       [ 0.06596369,  0.93403631],\n",
       "       [ 0.21685732,  0.78314269],\n",
       "       [ 0.26624555,  0.73375445],\n",
       "       [ 0.39537637,  0.60462363],\n",
       "       [ 0.11983884,  0.88016116],\n",
       "       [ 0.11047474,  0.88952526],\n",
       "       [ 0.05547511,  0.94452489],\n",
       "       [ 0.2339821 ,  0.7660179 ],\n",
       "       [ 0.23146846,  0.76853154],\n",
       "       [ 0.135106  ,  0.864894  ],\n",
       "       [ 0.13310892,  0.86689108],\n",
       "       [ 0.03320019,  0.96679981],\n",
       "       [ 0.05903626,  0.94096374],\n",
       "       [ 0.07660009,  0.92339991],\n",
       "       [ 0.05231927,  0.94768073],\n",
       "       [ 0.1680843 ,  0.8319157 ],\n",
       "       [ 0.10114251,  0.89885749],\n",
       "       [ 0.05166221,  0.9483378 ],\n",
       "       [ 0.03359685,  0.96640315],\n",
       "       [ 0.15700462,  0.84299538],\n",
       "       [ 0.10766687,  0.89233314],\n",
       "       [ 0.17366546,  0.82633454],\n",
       "       [ 0.08777069,  0.91222932],\n",
       "       [ 0.13164886,  0.86835114],\n",
       "       [ 0.15532827,  0.84467173],\n",
       "       [ 0.06337214,  0.93662787],\n",
       "       [ 0.11819554,  0.88180446],\n",
       "       [ 0.06807698,  0.93192302],\n",
       "       [ 0.06628545,  0.93371455],\n",
       "       [ 0.2267979 ,  0.7732021 ],\n",
       "       [ 0.09175177,  0.90824823],\n",
       "       [ 0.19099986,  0.80900013],\n",
       "       [ 0.09276835,  0.90723165],\n",
       "       [ 0.02965899,  0.97034102],\n",
       "       [ 0.11532779,  0.88467221],\n",
       "       [ 0.21698372,  0.78301628],\n",
       "       [ 0.13013766,  0.86986234],\n",
       "       [ 0.06968842,  0.93031158],\n",
       "       [ 0.14450367,  0.85549633],\n",
       "       [ 0.12257926,  0.87742074],\n",
       "       [ 0.26973683,  0.73026317],\n",
       "       [ 0.04859313,  0.95140687],\n",
       "       [ 0.10003161,  0.89996839],\n",
       "       [ 0.16565635,  0.83434365],\n",
       "       [ 0.07253064,  0.92746936],\n",
       "       [ 0.16421262,  0.83578738],\n",
       "       [ 0.1002629 ,  0.8997371 ],\n",
       "       [ 0.29457947,  0.70542053],\n",
       "       [ 0.24284214,  0.75715786],\n",
       "       [ 0.07095342,  0.92904658],\n",
       "       [ 0.22512369,  0.77487631],\n",
       "       [ 0.13801874,  0.86198126],\n",
       "       [ 0.09158669,  0.9084133 ],\n",
       "       [ 0.17410829,  0.82589172],\n",
       "       [ 0.09058124,  0.90941876],\n",
       "       [ 0.10733968,  0.89266032],\n",
       "       [ 0.25225974,  0.74774026],\n",
       "       [ 0.03438661,  0.96561339],\n",
       "       [ 0.05797717,  0.94202283],\n",
       "       [ 0.0875575 ,  0.9124425 ],\n",
       "       [ 0.31980422,  0.68019578],\n",
       "       [ 0.10494609,  0.89505391],\n",
       "       [ 0.50474709,  0.49525291],\n",
       "       [ 0.08118237,  0.91881763],\n",
       "       [ 0.23050603,  0.76949396],\n",
       "       [ 0.0675337 ,  0.9324663 ],\n",
       "       [ 0.09543111,  0.90456888],\n",
       "       [ 0.12765179,  0.8723482 ],\n",
       "       [ 0.16422209,  0.83577791],\n",
       "       [ 0.17526595,  0.82473405],\n",
       "       [ 0.06342064,  0.93657936],\n",
       "       [ 0.12916157,  0.87083843],\n",
       "       [ 0.09060347,  0.90939653],\n",
       "       [ 0.13708069,  0.86291931],\n",
       "       [ 0.20055055,  0.79944945],\n",
       "       [ 0.08364142,  0.91635858],\n",
       "       [ 0.08248665,  0.91751335],\n",
       "       [ 0.16782631,  0.83217369],\n",
       "       [ 0.22531396,  0.77468604],\n",
       "       [ 0.12916187,  0.87083813],\n",
       "       [ 0.12890906,  0.87109094],\n",
       "       [ 0.05851295,  0.94148705],\n",
       "       [ 0.07515589,  0.92484411],\n",
       "       [ 0.0722718 ,  0.9277282 ],\n",
       "       [ 0.12980391,  0.87019609],\n",
       "       [ 0.14785102,  0.85214898],\n",
       "       [ 0.46781567,  0.53218433],\n",
       "       [ 0.10186463,  0.89813537],\n",
       "       [ 0.10641165,  0.89358835],\n",
       "       [ 0.20195126,  0.79804874],\n",
       "       [ 0.1343117 ,  0.86568831],\n",
       "       [ 0.14446065,  0.85553934],\n",
       "       [ 0.19083894,  0.80916105],\n",
       "       [ 0.12913261,  0.87086739],\n",
       "       [ 0.0713751 ,  0.9286249 ],\n",
       "       [ 0.16055165,  0.83944835],\n",
       "       [ 0.14506588,  0.85493412],\n",
       "       [ 0.11426111,  0.88573889],\n",
       "       [ 0.07325318,  0.92674683],\n",
       "       [ 0.05336477,  0.94663523],\n",
       "       [ 0.28327963,  0.71672037],\n",
       "       [ 0.03431292,  0.96568708],\n",
       "       [ 0.10705022,  0.89294978],\n",
       "       [ 0.1182867 ,  0.8817133 ],\n",
       "       [ 0.09501545,  0.90498455],\n",
       "       [ 0.11515264,  0.88484736],\n",
       "       [ 0.06301026,  0.93698974],\n",
       "       [ 0.0868622 ,  0.9131378 ],\n",
       "       [ 0.15128621,  0.8487138 ],\n",
       "       [ 0.05505325,  0.94494675],\n",
       "       [ 0.14519252,  0.85480748],\n",
       "       [ 0.15756133,  0.84243867],\n",
       "       [ 0.08962354,  0.91037647],\n",
       "       [ 0.12996044,  0.87003956],\n",
       "       [ 0.36972188,  0.63027812],\n",
       "       [ 0.11484029,  0.88515971],\n",
       "       [ 0.09435309,  0.9056469 ],\n",
       "       [ 0.13778527,  0.86221473],\n",
       "       [ 0.6209777 ,  0.37902231],\n",
       "       [ 0.07957554,  0.92042446],\n",
       "       [ 0.08899281,  0.91100719],\n",
       "       [ 0.31722128,  0.68277872],\n",
       "       [ 0.32377618,  0.67622381],\n",
       "       [ 0.10363244,  0.89636755]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle_in = open(\"predictions_breast_sub_basal_vs_all_7layers_tr_test_epoch_1.pth.p\",\"rb\")\n",
    "dat = pickle.load(pickle_in)\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
